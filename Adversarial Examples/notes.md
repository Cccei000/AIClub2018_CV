## 攻击对象：
* 自己实现的一个简单的6层CNN.
* 前三层卷积层分别有8、16、20个filters，大小均为(5,5).  
* 后两层全连接层大小分别为(320,50)和(50,10).
* 数据集为MNIST，训练集大小为60000，batch为100，训练5轮.
* 最终在2000个测试数据上准确率达到99%.

## 对抗方案1：
### 训练：
* 一个比较直白的想法是反复训练一个噪声图像，使得它叠加在给定图像上得到的对抗样本代入CNN后，所得标签与给定标签的损失最小.
* 可以用反向传播+梯度下降法直接对噪声进行训练，为了控制干扰的大小，可在原先的交叉熵损失函数上补充一个惩罚项.
* 实现过程中发现训练过程十分缓慢，并且直接使用L2范数做惩罚项效果不好并且很难调控，故使用均值做惩罚项，并对损失进行系数修正.
* 为了进一步控制噪声大小，对干扰进行了截断使其保持在一定范围内.
* 最终版本中，使用SGD进行梯度下降，学习率为0.1，动量系数为0.9。交叉熵系数为5000，均值惩罚项系数为100。截断范围为(-15,15).
### 测试：
* 测试效果时，固定取原训练集的前100个数据作为被攻击的数据，对其中的每一个随机分配一个与其真实标签不同的目标标签，用500个iteration生成一个噪声图像。如果CNN给予对抗样本的标签与目标标签相同，则记1次攻击成功。最终给出攻击的成功率和成功噪声图像的平均L2范数.
* 最终的结果：攻击的成功率为58%，成功案例的平均L2范数为391.
* 一个成功案例：真实标签为5，目标标签为9，CNN预测标签为9，噪声L2范数为393。从左到右分别为原始图像、对抗样本、噪声图像：  
![](https://raw.githubusercontent.com/Cei1ing/AIClub2018_CV/master/Adversarial%20Examples/adversarial_v1.JPG)  

## 对抗方案2：
### 训练：
* 采用FGSM的方法，对抗样本x_n+1 = x_n - lr\*sign(x_n.grad)，并控制对抗样本在原始图像加减eps范围内，且整体在[0,255]内.
* 最终版本中，使用交叉熵作为损失函数，没有修正系数，没有惩罚项，lr取1，eps取25.
### 测试：
* 测试方式与先前相同，最终的攻击成功率为50%，成功案例的平均L2范数为477.
* 一个成功案例：真实标签为7，目标标签为2，CNN预测标签为2，噪声L2范数为479。从左到右分别为原始图像、对抗样本、噪声图像：  
![](https://raw.githubusercontent.com/Cei1ing/AIClub2018_CV/master/Adversarial%20Examples/adversarial_v2.JPG)  

## 总结：
1. 进一步学习并熟悉了pytorch的各种特性和功能.
2. 实践了一次从分析问题、提出方法、代码实现到细节优化与再生产的过程.
3. 最终的对抗效果还是没有达到预期目标，成功率不够，噪声大小还是肉眼可见的，参考了网上一些效果惊艳的FGSM代码进行修改，包括进行归一化和根据梯度调整步长，但是都不起作用，原因有待进一步研究.
